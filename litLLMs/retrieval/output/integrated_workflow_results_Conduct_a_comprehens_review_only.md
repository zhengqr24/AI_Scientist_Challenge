# The Rise of Spatio-Temporal Foundation Models: Architectural Paradigms, Scaling Laws, and Cross-Domain Applications (2024-Present)

## 1 Introduction: The New Frontier of Spatio-Temporal Intelligence

Spatio-temporal prediction represents one of the most challenging and consequential problems in artificial intelligence, encompassing the forecasting of phenomena that evolve across both space and time dimensions. From traffic flow and weather patterns to disease spread and environmental monitoring, the ability to accurately predict spatio-temporal dynamics has profound implications across numerous scientific and industrial domains [1]. The core challenge lies in effectively modeling the complex interplay between spatial autocorrelation—where nearby locations exhibit similar characteristics—and temporal dynamics that may include seasonality, trends, and complex nonlinear dependencies. Traditional approaches have typically relied on specialized architectures tailored to specific domains, such as convolutional neural networks (CNNs) for spatial grid data, recurrent neural networks (RNNs) for temporal sequences, and graph neural networks (GNNs) for irregular spatial structures [2].

The historical paradigm of task-specific modeling has proven increasingly inadequate for addressing the scale and complexity of modern spatio-temporal problems. These specialized models suffer from limited generalization capabilities, requiring extensive retraining and architectural modifications when applied to new domains or even slightly different tasks within the same domain. This limitation becomes particularly pronounced in real-world scenarios where data distributions may shift over time or where models must adapt to previously unseen spatial configurations. The computational inefficiency of training separate models for each prediction task further compounds these challenges, especially given the exponential growth in spatio-temporal data from sources such as satellite networks, IoT sensors, and urban monitoring systems [3].

The year 2024 has marked a transformative paradigm shift with the emergence of Spatio-Temporal Foundation Models (STFMs) and Large Spatio-Temporal Models (LSTMs), representing a fundamental reimagining of how we approach spatio-temporal intelligence. Drawing inspiration from the success of foundation models in natural language processing and computer vision, STFMs are characterized by their massive scale, extensive pre-training on diverse spatio-temporal datasets, and ability to perform zero-shot or few-shot adaptation to a wide range of downstream prediction tasks [4]. These models aim to capture universal patterns and representations that transcend specific domains, enabling unprecedented generalization capabilities and reducing the need for task-specific engineering. The distinction between STFMs and LSTMs, while sometimes blurred, generally reflects a spectrum where STFMs serve as generalized backbones for representation learning, while LSTMs typically incorporate additional reasoning capabilities and operate at even larger scales [5].

This comprehensive review synthesizes and critically analyzes the rapid advancements in spatio-temporal foundation models since 2024, with particular emphasis on architectural innovations, scaling properties, and emergent capabilities. We establish a coherent taxonomy to navigate the diverse landscape of approaches, provide detailed methodological comparisons across multiple dimensions, and examine cross-domain applications that demonstrate the transformative potential of these models. Through extensive case studies and critical analysis, we aim to chart both the current state of the field and its future trajectories, while highlighting the significant challenges that remain unresolved.

## 2 Foundational Concepts and a Unifying Taxonomy

### 2.1 Core Architectural Components of STFMs

The architectural foundation of modern spatio-temporal models rests on three fundamental components: spatial encoders, temporal encoders, and fusion mechanisms that integrate these representations. Spatial encoders have evolved significantly beyond traditional CNNs, with Graph Neural Networks (GNNs) becoming increasingly prominent for handling irregular spatial structures such as road networks, sensor placements, and geographic features. The most recent innovation in this space comes from the integration of State Space Models (SSMs), particularly the Mamba architecture, which offers compelling advantages for capturing long-range spatial dependencies [1]. The OBIA-Mamba approach exemplifies this trend, utilizing superpixels as Mamba tokens within a global-local framework to efficiently model spatial relationships while reducing computational redundancy.

Temporal encoders have similarly undergone substantial evolution, moving from recurrent architectures like LSTMs and GRUs toward transformer-based models that can capture complex temporal dependencies through self-attention mechanisms. However, the quadratic complexity of standard transformers has prompted the development of more efficient alternatives, including temporal convolutional networks (TCNs) and most recently, temporal SSMs that maintain linear scaling with sequence length [6]. These advancements are particularly crucial for spatio-temporal prediction, where modeling long-term dependencies is often essential for accurate forecasting.

The fusion problem—how to effectively combine spatial and temporal representations—represents one of the most challenging aspects of STFM design. Early fusion approaches combine raw spatial and temporal inputs at the input level, while late fusion processes spatial and temporal patterns independently before combining them at the output stage. Intermediate fusion, which has gained prominence in recent architectures, integrates spatial and temporal representations throughout the network, allowing for more nuanced interactions between these modalities [7]. The Latent Upscaler Adapter (LUA) exemplifies an innovative approach to fusion, performing multi-scale integration directly in the latent space rather than in pixel space, thereby achieving significant efficiency gains while maintaining representation quality.

### 2.2 Defining the Spectrum: From Specialized to Foundational

The distinction between specialized models, spatio-temporal foundation models, and large spatio-temporal models requires careful delineation based on specific criteria. We propose that a model qualifies as a foundation model if it demonstrates: (1) pre-training on massive, diverse spatio-temporal datasets spanning multiple domains; (2) parameter counts sufficient to capture complex spatio-temporal patterns (typically >100M parameters); (3) task-agnostic representations that support zero-shot or few-shot adaptation; and (4) emergent abilities not explicitly programmed during training [4]. Large Spatio-Temporal Models (LSTMs) represent a further evolution, characterized by even greater scale (typically >1B parameters) and often incorporating integrated reasoning capabilities that enable more sophisticated understanding of spatio-temporal phenomena [8].

Within this spectrum, hybrid architectures have emerged as particularly promising approaches that integrate STFMs with other modalities such as vision and language [5]. These models leverage the complementary strengths of different foundation models, enabling more comprehensive understanding of complex spatio-temporal scenarios. For instance, vision-augmented STFMs can incorporate satellite imagery and ground-level photos to enrich spatial representations, while language-augmented variants can interpret textual context to inform temporal predictions. The SmolVLM2 architecture demonstrates how such integration can be achieved even under resource constraints, making foundation model capabilities accessible for applications with limited computational resources [5].

Our proposed taxonomy differentiates between three primary categories: Spatio-Temporal Foundation Models (STFMs) as generalized backbones for representation learning; Large Spatio-Temporal Models (LSTMs) with enhanced scale and reasoning capabilities; and Hybrid Architectures that integrate STFMs with other modalities. This taxonomy provides a structured framework for understanding the diverse landscape of approaches and their respective strengths and limitations, which we will explore in detail throughout this review.

## 3 Architectural Paradigms for Large-Scale Spatio-Temporal Learning

### 3.1 The Transformer Ascendancy and Its Scalability Challenge

The transformer architecture, which revolutionized natural language processing, has similarly transformed spatio-temporal modeling through its ability to capture complex dependencies across both spatial and temporal dimensions. When applied to spatio-temporal data, transformers typically treat each spatial location at each time step as a token, allowing the model to learn rich interactions through self-attention mechanisms. This approach has demonstrated remarkable success in domains ranging from traffic prediction to climate modeling, where capturing long-range dependencies is crucial for accurate forecasting [4].

However, the widespread adoption of transformers in spatio-temporal domains has revealed significant scalability challenges. The self-attention mechanism at the core of transformers exhibits quadratic complexity with respect to sequence length, making it computationally prohibitive for applications involving high-resolution spatial data or long temporal sequences. This limitation becomes particularly acute in real-world scenarios such as city-wide traffic prediction or continental-scale weather forecasting, where both spatial and temporal dimensions can be extensive. The memory requirements for storing attention matrices grow exponentially, constraining the practical applicability of vanilla transformers to relatively small-scale problems [6].

Recent efforts to address these limitations have focused on developing efficient attention variants, including sparse attention patterns, linear attention approximations, and hierarchical approaches that process data at multiple resolutions. While these methods have achieved notable improvements in efficiency, they often come at the cost of representational capacity or require careful engineering to maintain performance. The fundamental tension between computational efficiency and modeling capacity remains a central challenge in transformer-based spatio-temporal modeling, prompting exploration of alternative architectural paradigms that can overcome these limitations [1].

### 3.2 The State Space Model (SSM) Revolution

The emergence of State Space Models (SSMs), particularly the Mamba architecture, represents a paradigm shift in sequential modeling with profound implications for spatio-temporal prediction. SSMs draw inspiration from classical control theory, modeling sequential data through latent states that evolve over time according to learned dynamics. The key innovation in modern SSMs lies in their parameterization of these dynamics as input-dependent processes, enabling the model to selectively propagate or forget information based on the current context [1]. This selective mechanism allows SSMs to maintain long-range dependencies while operating with linear complexity in sequence length, addressing a fundamental limitation of transformer architectures.

The mathematical foundation of SSMs centers on continuous-time systems described by linear ordinary differential equations, which are then discretized for digital computation. This continuous-time perspective provides theoretical advantages for modeling irregularly sampled temporal data, a common characteristic of real-world spatio-temporal datasets where measurements may be missing or collected at varying intervals. The discretization process involves learned parameters that control how much information from previous states is retained, creating a dynamic memory mechanism that adapts to the input sequence [1].

A compelling case study of SSM application in spatio-temporal domains is the OBIA-Mamba architecture for Sentinel-2 landcover mapping [1]. This approach introduces several innovative elements: first, it employs superpixels generated through Object-Based Image Analysis (OBIA) as tokens for the Mamba model, effectively reducing computational redundancy while preserving fine-grained spatial details. Second, it implements a global-local (GLocal) dual-branch architecture that combines CNN-based local feature extraction with Mamba-based global context modeling. Third, it incorporates a multitask optimization framework that balances local precision with global consistency through dual loss functions. Empirical results demonstrate that this approach achieves superior classification accuracy compared to transformer-based alternatives while requiring significantly less computational resources, highlighting the practical advantages of SSMs for large-scale spatio-temporal applications [1].

### 3.3 Latent Space Manipulation for Efficiency

The paradigm of latent space manipulation has emerged as a powerful strategy for enhancing the efficiency of spatio-temporal models while maintaining representational quality. Traditional approaches to tasks such as super-resolution or scale adaptation typically operate in pixel space, requiring expensive computations across high-dimensional representations. Recent advances have demonstrated that performing these operations in compressed latent spaces can achieve comparable quality with substantially reduced computational requirements [7].

The Latent Upscaler Adapter (LUA) represents a groundbreaking approach in this direction, performing super-resolution directly on the generator's latent code before the final decoding step [7]. This architecture employs a shared Swin-style backbone with scale-specific pixel-shuffle heads that support both 2x and 4x upscaling factors. By operating in the latent space, LUA avoids the computational overhead of processing high-resolution pixel arrays while maintaining perceptual quality comparable to pixel-space methods. The efficiency gains are substantial: LUA reduces decoding and upscaling time by nearly 3x compared to traditional super-resolution approaches, adding only 0.42 seconds for 1024px generation from 512px inputs versus 1.87 seconds for pixel-space alternatives [7].

The implications of latent space manipulation extend beyond image super-resolution to broader spatio-temporal prediction tasks. In weather and climate modeling, for instance, similar approaches could enable efficient downscaling of global climate predictions to regional or local scales without the computational expense of running high-resolution physical simulations. The principle of performing computationally intensive operations in compressed latent representations represents a generalizable strategy for scaling spatio-temporal models to higher resolutions and larger domains while maintaining practical computational requirements [7].

### 3.4 Simulation-Based Inference as a Pre-Training Paradigm

Simulation-based inference (SBI) has emerged as a powerful paradigm for training spatio-temporal models, particularly in domains where real-world data is scarce, expensive to acquire, or lacks comprehensive ground truth. SBI leverages physically realistic simulations to generate synthetic training data that captures the essential dynamics of the target system, enabling models to learn robust representations without extensive real-world supervision [9].

The Synference framework for galaxy spectral energy distribution (SED) fitting provides an exemplary case study of SBI applied to a complex spatio-temporal-like problem [9]. This approach trains a neural posterior estimator on 10^6 simulated galaxies based on a flexible 8-parameter physical model, enabling rapid inference of galaxy properties from multi-band photometry. The amortized inference achieved by Synference is exceptionally efficient, processing entire galaxy samples in approximately 3 minutes on a single CPU—a 1700x speedup over traditional nested sampling or MCMC techniques [9]. This dramatic acceleration demonstrates the potential of SBI for enabling real-time or near-real-time spatio-temporal prediction in domains where traditional inference methods would be computationally prohibitive.

The relevance of SBI to spatio-temporal foundation models lies in its potential as a pre-training paradigm. By training on diverse simulations that capture fundamental physical principles, STFMs can develop generalizable representations that transfer effectively to real-world data. This approach is particularly valuable in domains such as climate science, urban planning, and epidemiology, where comprehensive simulations exist but real-world observations may be limited or noisy. The success of Synference in astrophysics suggests that similar approaches could be fruitfully applied to Earth-scale spatio-temporal problems, leveraging physical simulations to bootstrap foundation model capabilities [9].

## 4 The Scaling Law: Data, Compute, and Emergent Abilities

### 4.1 The Drive for Scale: Parameter Count and Training Data

The scaling hypothesis—that model performance improves predictably with increases in model size, dataset size, and computational resources—has been dramatically validated in natural language processing and computer vision, and is now being tested in spatio-temporal domains. The Instella language model family demonstrates this principle in adjacent domains, achieving state-of-the-art performance through careful scaling of model parameters and training data despite using fewer pre-training tokens than many contemporaries [4]. This success has inspired similar scaling efforts in spatio-temporal modeling, with recent STFMs pushing parameter counts into the hundreds of millions and training on petabytes of diverse spatio-temporal data.

The curation of massive, heterogeneous spatio-temporal datasets presents unique challenges compared to language or image data. Spatio-temporal datasets often exhibit complex dependencies across multiple scales, irregular sampling patterns, and significant missing data. Furthermore, the integration of diverse data sources—from satellite imagery and IoT sensor networks to traffic cameras and social media feeds—requires sophisticated preprocessing and alignment techniques to create coherent training corpora [3]. The temporal dimension introduces additional complexities, as models must handle non-stationary distributions, concept drift, and varying sampling rates across different data sources.

The computational requirements for training large-scale STFMs are substantial, often requiring distributed training across hundreds or thousands of accelerators for extended periods. The ParoQuant quantization method offers promising directions for mitigating these requirements through pairwise rotation quantization that evens out magnitude across channels and narrows dynamic range within quantization groups [6]. This approach achieves 2.4% accuracy improvement over previous quantization methods with less than 10% overhead, making large-scale spatio-temporal model deployment more practical. Such efficiency improvements are crucial for enabling broader access to STFM capabilities, particularly for resource-constrained applications or organizations [6].

### 4.2 Evidence of Emergent Abilities

As spatio-temporal foundation models scale in size and training data, researchers have begun observing emergent abilities—capabilities that arise unexpectedly without explicit programming or training. These emergent properties mirror phenomena observed in large language models, where scaling enables qualitatively new behaviors such as reasoning, in-context learning, and compositional understanding [8]. In spatio-temporal domains, emergent abilities may manifest as zero-shot spatial interpolation, where models can predict values at unobserved locations based on patterns learned from different geographic contexts; temporal extrapolation beyond training distributions; and cross-domain transfer, where representations learned from one domain (e.g., traffic patterns) prove effective in unrelated domains (e.g., disease spread).

The Socratic Self-Refine (SSR) framework, though developed for language model reasoning, offers a compelling blueprint for how emergent reasoning capabilities might be cultivated in spatio-temporal models [8]. SSR decomposes model responses into verifiable (sub-question, sub-answer) pairs, enabling step-level confidence estimation through controlled re-solving and self-consistency checks. Applied to spatio-temporal prediction, similar approaches could enable models to identify and refine unreliable components of their forecasts, leading to more accurate and interpretable predictions. The empirical success of SSR across multiple reasoning benchmarks suggests that structured refinement mechanisms may be essential for unlocking the full potential of emergent reasoning in complex domains [8].

Another promising direction for emergent abilities in STFMs involves the integration of causal reasoning frameworks that enable models to understand not just correlations but underlying causal mechanisms in spatio-temporal systems. The Resonance Principle proposes that genuine causal understanding emerges in stochastic, bounded agents with intrinsic cost functions, modeled as networks of weakly coupled oscillators where action proposals arise as stable resonant modes [10]. While developed in the context of neural processing, this principle may inform the design of STFMs that can reason about interventions and counterfactuals in complex spatio-temporal systems, moving beyond pattern recognition toward genuine understanding of dynamical processes [10].

### 4.3 The Critical Role of Efficient Scaling

The pursuit of scale in spatio-temporal foundation models must be balanced against practical constraints of computational resources, energy consumption, and deployment scenarios. Efficient scaling strategies have therefore become a critical focus of research, with innovations in model compression, quantization, and distillation playing essential roles in making large models practically usable [6]; [11].

Black-box on-policy distillation represents a particularly promising approach for transferring capabilities from large teacher models to more efficient student models without access to the teacher's internal parameters or logits [11]. The Generative Adversarial Distillation (GAD) framework frames the student model as a generator and trains a discriminator to distinguish its responses from the teacher's, creating a minimax game that drives improvement. This approach has demonstrated remarkable success in language domains, with distilled models achieving performance comparable to much larger teachers on automatic evaluation metrics [11]. Applied to spatio-temporal domains, similar distillation techniques could enable the deployment of foundation model capabilities in resource-constrained environments such as edge devices, drones, or mobile sensors, dramatically expanding the practical applicability of STFMs.

Quantization methods like ParoQuant further enhance efficiency by compressing model weights into low-precision representations while minimizing accuracy degradation [6]. The presence of outliers in weights and activations presents particular challenges for quantization, especially in reasoning models where errors accumulate across long chains of computation. ParoQuant addresses this through pairwise rotation quantization combined with channel-wise scaling, achieving significant accuracy improvements over previous methods with minimal inference overhead. These advances in efficient scaling are not merely optional optimizations but essential enablers for the practical deployment of spatio-temporal foundation models across diverse real-world applications [6].

## 5 A Detailed Comparative Analysis of Methodologies

### 5.1 Comparison Framework

To enable systematic comparison across the diverse landscape of spatio-temporal foundation models, we establish a comprehensive framework based on six key dimensions: (1) Architectural Family (Transformer, SSM, Hybrid, etc.); (2) Core Innovation (novel components or training paradigms); (3) Scalability (time and space complexity characteristics); (4) Handling of Long-Range Dependencies (mechanisms for capturing extended spatial and temporal contexts); (5) Primary Application Domain (environmental, urban, biomedical, etc.); and (6) Key Limitations (computational requirements, data dependencies, or domain restrictions). This framework allows us to identify patterns across different approaches and understand the trade-offs involved in architectural decisions.

The comparative analysis reveals distinct clusters of methods optimized for different scenarios. Transformer-based approaches excel in scenarios requiring rich interaction modeling across spatial and temporal dimensions but struggle with computational complexity at scale. SSM-based methods offer compelling alternatives for long-sequence modeling with linear complexity but may require careful design to capture complex spatial relationships. Hybrid architectures attempt to combine the strengths of multiple approaches but introduce additional complexity in training and deployment. Understanding these trade-offs is essential for selecting appropriate architectures for specific spatio-temporal prediction tasks [1].

### 5.2 In-Depth Method vs. Method Analysis

#### Transformer-based vs. SSM-based Architectures

The comparison between transformer-based and SSM-based approaches represents one of the most significant architectural decisions in contemporary spatio-temporal modeling. Transformer architectures, with their self-attention mechanisms, excel at capturing complex, non-local dependencies across both space and time. This makes them particularly well-suited for tasks requiring rich contextual understanding, such as predicting complex urban dynamics or understanding intricate climate patterns. However, their quadratic complexity imposes practical limits on sequence length, constraining their application to high-resolution spatial data or long temporal histories [4].

In contrast, SSM-based approaches like Mamba offer linear scaling with sequence length, making them capable of handling extremely long spatio-temporal sequences that would be computationally prohibitive for transformers. The OBIA-Mamba architecture demonstrates this advantage in landcover mapping, where it processes high-resolution satellite imagery efficiently by treating superpixels as tokens [1]. The selective state space mechanism in Mamba allows it to dynamically focus on relevant context while ignoring irrelevant information, a property particularly valuable in spatio-temporal domains where only certain spatial or temporal contexts may be relevant for prediction at a given location and time.

The key differentiators between these approaches extend beyond computational complexity to their fundamental inductive biases. Transformers impose minimal structural assumptions, allowing them to learn complex dependency patterns from data but requiring substantial training data to do so effectively. SSMs incorporate stronger structural priors through their state space formulation, which can be advantageous in data-limited scenarios or when modeling systems with known dynamical characteristics. In practice, the choice between these architectures depends on the specific requirements of the application, including sequence length, available training data, and the complexity of dependencies that must be captured [1].

#### Latent-Space Efficiency vs. Pixel-Space Methods

The comparison between latent-space and pixel-space operations represents another critical dimension in spatio-temporal model design, with significant implications for efficiency and scalability. Traditional pixel-space methods operate directly on high-dimensional raw data, providing fine-grained control but requiring substantial computational resources. The Latent Upscaler Adapter (LUA) exemplifies the latent-space alternative, performing super-resolution in compressed representations before final decoding [7].

The efficiency advantages of latent-space methods are substantial: LUA reduces decoding and upscaling time by nearly 3x compared to pixel-space alternatives while maintaining comparable perceptual quality [7]. This efficiency gain becomes increasingly important as model resolutions scale, making latent-space approaches particularly valuable for applications requiring high-resolution predictions over large spatial extents, such as regional climate modeling or city-scale urban simulation.

However, latent-space methods introduce their own challenges, particularly regarding interpretability and control. Operations in latent space are less transparent than their pixel-space counterparts, making it difficult to understand how specific manipulations affect the final output. Additionally, the compression inherent in latent representations may lose fine-grained details that could be important for certain applications. The choice between latent-space and pixel-space approaches therefore involves trade-offs between efficiency and transparency, with the optimal balance depending on the specific requirements of the application [7].

#### Simulation-Based vs. Real-Data Driven Pre-training

The paradigm for pre-training spatio-temporal foundation models represents another fundamental axis of variation, with simulation-based and real-data driven approaches offering complementary advantages and limitations. Simulation-based approaches, exemplified by Synference in astrophysics, leverage physically-based models to generate synthetic training data that captures the essential dynamics of the target system [9]. This approach offers several advantages: virtually unlimited training data, perfect ground truth labels, and the ability to explore rare or extreme scenarios that may be poorly represented in real-world datasets.

However, simulation-based pre-training faces the fundamental challenge of the sim-to-real gap—discrepancies between simulated and real data that can limit model performance when deployed in real-world settings. These discrepancies may arise from simplifications in the physical models, imperfect parameterizations, or missing processes in the simulations. Bridging this gap requires careful calibration of simulations against real observations and may involve domain adaptation techniques to align representations between simulated and real domains [9].

Real-data driven pre-training avoids the sim-to-real gap by learning directly from observational data, but faces challenges of data scarcity, noise, and incomplete ground truth. In many spatio-temporal domains, comprehensive real-world datasets are difficult or expensive to acquire, and may lack the diversity needed for robust generalization. Furthermore, observational data often contains systematic biases and missing values that can distort learned representations if not properly addressed [3].

The most promising approaches may combine both paradigms, using simulation-based pre-training to establish foundational understanding of physical principles followed by fine-tuning on real-world data to adapt to observational characteristics. This hybrid approach leverages the strengths of both methods while mitigating their respective limitations, offering a path toward models that are both physically consistent and practically effective [9].

#### Specialized vs. General-Purpose Models

The tension between specialized and general-purpose models represents a recurring theme in machine learning, with particular relevance to spatio-temporal prediction. Specialized models, such as those optimized for UAV path planning in post-disaster scenarios, are highly optimized for specific tasks and domains, often achieving state-of-the-art performance within their narrow scope [2]. These models can incorporate domain-specific inductive biases and exploit task-specific structure to achieve high efficiency and accuracy.

However, specialized models suffer from limited generalization capabilities, requiring extensive re-engineering when applied to new domains or even slightly different tasks within the same domain. This limitation becomes particularly problematic in real-world scenarios where requirements may evolve over time or where models must adapt to changing conditions. The development and maintenance of multiple specialized models for different spatio-temporal prediction tasks can also be resource-intensive and impractical for organizations with diverse needs [2].

General-purpose spatio-temporal foundation models offer an alternative approach, aiming to develop unified representations that transfer across domains and tasks. These models sacrifice some degree of task-specific optimization in exchange for broader applicability and reduced need for custom engineering. The emergence of zero-shot and few-shot capabilities in foundation models further enhances their practical value, enabling adaptation to new tasks with minimal additional training [1].

The optimal balance between specialization and generalization depends on the specific application context, including the diversity of tasks, availability of training data, and requirements for peak performance versus flexibility. In practice, many successful deployments may involve a combination of general-purpose foundation models for broad understanding with specialized components for task-specific refinement, creating hybrid architectures that leverage the strengths of both approaches [2].

## 6 Cross-Domain Applications and Case Studies

### 6.1 Environmental Science and Earth Observation

The application of spatio-temporal foundation models to environmental science and Earth observation represents one of the most promising and impactful domains, with potential applications in climate modeling, ecosystem monitoring, and natural disaster prediction. The OBIA-Mamba architecture for Sentinel-2 landcover mapping demonstrates the capabilities of modern STFMs in processing complex satellite imagery to produce detailed classification maps [1]. This approach addresses key challenges in remote sensing, including spatial heterogeneity, contextual information integration, and signature ambiguity through its global-local architecture and multitask optimization framework.

Beyond landcover classification, STFMs show considerable promise for climate modeling and weather prediction. Traditional numerical weather prediction models rely on complex physical simulations that are computationally intensive and may struggle to capture certain nonlinear processes. Data-driven approaches using foundation models offer complementary capabilities, potentially capturing patterns that are difficult to model explicitly while offering substantially faster inference times. The latent space manipulation techniques exemplified by LUA could be particularly valuable in this domain, enabling efficient downscaling of global climate predictions to regional or local scales [7].

The integration of diverse data sources represents another significant opportunity for STFMs in environmental science. By combining satellite imagery, ground-based sensor networks, atmospheric measurements, and even social media feeds, foundation models can develop comprehensive understanding of environmental systems that transcends what is possible from any single data source. The querying capabilities demonstrated in scenario program analysis of time series data could be adapted to environmental monitoring, enabling efficient identification of specific patterns or events across massive spatio-temporal datasets [3].

### 6.2 Urban Computing and Intelligent Transportation

Urban environments generate vast amounts of spatio-temporal data from sources including traffic sensors, surveillance cameras, mobility services, and infrastructure monitoring systems, creating rich opportunities for foundation model applications. Traffic prediction represents a canonical problem in this domain, requiring the modeling of complex spatial networks and temporal patterns across multiple scales. Traditional approaches often struggle with long-range dependencies and rare events, limitations that STFMs are particularly well-suited to address through their ability to capture complex patterns across extended spatial and temporal contexts [2].

The optimization of UAV flight paths for post-disaster reconnaissance demonstrates how spatio-temporal modeling can inform decision-making in critical scenarios [2]. This application requires reasoning about multiple constraints, including sensor coverage, uncertainty minimization, and operational limitations, within highly dynamic and unstructured environments. Foundation models with integrated reasoning capabilities, potentially enhanced through frameworks like SSR, could significantly improve such optimization tasks by considering a broader range of factors and anticipating second-order effects [8].

Urban planning and infrastructure management represent longer-term applications where STFMs could provide valuable insights by modeling the evolution of urban systems over extended time horizons. By learning from historical data across multiple cities, foundation models could identify patterns of urban development, predict the impact of policy interventions, and optimize infrastructure investments. The ability to perform counterfactual reasoning would be particularly valuable in this context, enabling planners to explore the potential outcomes of different decisions before implementation [2].

### 6.3 Healthcare and Epidemiology

The COVID-19 pandemic highlighted the critical importance of spatio-temporal modeling in understanding and managing disease spread, with foundation models offering potential enhancements to traditional epidemiological approaches. By integrating diverse data sources including case reports, mobility patterns, environmental factors, and healthcare capacity, STFMs could provide more accurate predictions of disease dynamics and more effective guidance for intervention strategies [12].

The M&M-3D architecture for cancer detection in Digital Breast Tomosynthesis demonstrates how spatio-temporal reasoning can enhance medical imaging analysis [12]. This approach constructs malignancy-guided 3D features and learns 3D reasoning through repeated mixing of these features with slice-level information, achieving significant improvements over 2D projection and 3D slice-based methods while remaining parameter-free relative to its 2D counterpart. The success of this architecture suggests potential applications in other medical imaging modalities where volumetric reasoning is essential, such as CT and MRI analysis [12].

Beyond medical imaging, STFMs show promise for modeling physiological processes that evolve across both space and time, such as neural activity, cardiac function, and disease progression. The Resonance Principle, which links phase synchronization in neural oscillators to emergent causal understanding, offers a theoretical framework that could inform the development of foundation models for complex biological systems [10]. By capturing the spatio-temporal dynamics of physiological processes, such models could enhance diagnosis, treatment planning, and fundamental biological understanding.

### 6.4 Fundamental Science and Discovery

Spatio-temporal foundation models are increasingly being applied to fundamental scientific problems across physics, chemistry, and materials science, where they can help uncover patterns that may be difficult to discern through traditional analysis. In cosmology, for instance, STFMs could enhance the analysis of large-scale structure formation, cosmic microwave background data, and galaxy evolution [13]; [9]. The Synference framework for galaxy SED fitting demonstrates how simulation-based inference can accelerate scientific discovery in astrophysics, and similar approaches could be applied to other domains where physical simulations are available [9].

In materials science, the unsupervised machine learning framework for analyzing excitonic landscapes in monolayer lateral heterostructures shows how STFMs can extract meaningful patterns from complex experimental data [14]. By combining principal component analysis, t-SNE, and density-based spatial clustering, this approach identifies spectrally distinct domains associated with composition, strain, and defect variations in 2D materials. The automation of such analysis through foundation models could dramatically accelerate materials characterization and discovery [14].

Quantum materials represent another domain where STFMs could provide valuable insights, particularly in understanding the complex interplay of electronic and structural degrees of freedom. The study of polar lattice vibrations in KTaO₃ and SrTiO₃ reveals rich spatio-temporal dynamics that could be captured more comprehensively through foundation models [15]. Similarly, the investigation of novel quantum states like the supernematic phase driven by combinatorial constraints could benefit from data-driven approaches that identify patterns across different parameter regimes and experimental conditions [16].

## 7 Critical Challenges and Future Directions

### 7.1 Data Quality, Heterogeneity, and Integration

The development of robust spatio-temporal foundation models faces significant challenges related to data quality, heterogeneity, and integration. Real-world spatio-temporal datasets often exhibit complex issues including missing values, systematic biases, varying resolutions, and inconsistent sampling patterns. These challenges are compounded when integrating data from multiple sources, which may use different coordinate systems, temporal references, and measurement protocols [3]. The querying of labeled time series data with scenario programs offers one approach to addressing these challenges, providing formal methods for identifying relevant patterns across heterogeneous datasets [3].

The problem of non-stationary noise presents particular difficulties for spatio-temporal modeling, as traditional assumptions of stationarity are often violated in real-world systems. The analysis of wavelet domain noise covariance matrices in gravitational wave detection provides insights that could inform more robust approaches to handling non-stationarity in broader spatio-temporal contexts [17]. By understanding the conditions under which noise correlation matrices can be approximated as diagonal, researchers can develop more effective preprocessing and modeling strategies for non-stationary spatio-temporal data.

Future directions in data handling for STFMs likely involve the development of more sophisticated methods for quality assessment, imputation, and alignment across heterogeneous sources. Self-supervised approaches that learn robust representations despite data imperfections offer particular promise, as do methods that explicitly model uncertainty and confidence in predictions. The integration of physical constraints and domain knowledge could further enhance data handling by providing principled guidance for addressing gaps and inconsistencies [3].

### 7.2 Computational and Infrastructure Requirements

The computational demands of training and deploying large-scale spatio-temporal foundation models present substantial practical challenges that must be addressed for widespread adoption. The ParoQuant quantization method demonstrates one approach to mitigating these demands through efficient weight compression, but additional innovations are needed across the entire model lifecycle from training to inference [6]. The impacts of decoder latency on quantum computer architectures, though focused on a different domain, highlight general principles about the relationship between computational speed and system performance that are relevant to classical computing as well [18].

Distributed training strategies represent another critical area for innovation, particularly as model sizes continue to increase. Efficient parallelization across hundreds or thousands of accelerators requires careful attention to communication patterns, memory usage, and load balancing. The Black-Box On-Policy Distillation approach offers an alternative path to capability development that may reduce training requirements by leveraging existing large models as teachers [11]. This method could be particularly valuable for organizations with limited computational resources, enabling them to develop capable spatio-temporal models without the expense of training from scratch.

The deployment of STFMs in resource-constrained environments such as edge devices, drones, or mobile sensors presents additional challenges related to memory, power consumption, and inference speed. The SmolVLM2 evaluation on mobile devices demonstrates that even large vision-language models can be adapted for mobile deployment through careful optimization and quantization [5]. Similar approaches could enable the deployment of spatio-temporal foundation capabilities in field applications where cloud connectivity may be limited or latency requirements demand local processing.

### 7.3 Interpretability, Accountability, and Ethical Considerations

As spatio-temporal foundation models are increasingly deployed in high-stakes applications such as urban planning, healthcare, and environmental management, ensuring their interpretability and accountability becomes critically important. The black-box nature of many deep learning models poses challenges for understanding how predictions are generated and for identifying potential sources of error or bias. The Socratic Self-Refine framework offers one approach to enhancing interpretability by decomposing reasoning into verifiable steps and enabling pinpoint refinement of unreliable components [8].

The model-oriented graph distances framework provides a formal foundation for comparing and evaluating graphical models, which could be extended to spatio-temporal representations [19]. By treating graphs as statistical models and organizing them in partially ordered sets based on model inclusion, this approach induces a neighborhood structure that supports meaningful distance metrics. Similar formalisms could enhance our understanding of how different spatio-temporal representations capture underlying processes and support more systematic model evaluation and selection.

Ethical considerations in spatio-temporal modeling include concerns about privacy, fairness, and potential misuse. Models that predict individual mobility patterns or property values could reveal sensitive information or perpetuate existing biases if not carefully designed and validated. The development of ethical frameworks and technical safeguards for spatio-temporal foundation models represents an important direction for future research, requiring collaboration across computer science, social sciences, and domain experts [2].

### 7.4 Integration with Physical Principles and Causal Reasoning

A fundamental limitation of many current data-driven approaches to spatio-temporal prediction is their reliance on correlation rather than causation, which can lead to unreliable predictions when conditions change or interventions are applied. Integrating physical principles and causal reasoning capabilities represents a crucial direction for advancing the field beyond pattern recognition toward genuine understanding of spatio-temporal dynamics [10].

The Resonance Principle proposes that causal understanding emerges in stochastic, bounded agents with intrinsic cost functions, modeled as networks of weakly coupled oscillators [10]. This theoretical framework, supported by empirical evidence from neural data, suggests directions for designing STFMs that can reason about interventions and counterfactuals rather than merely extrapolating patterns. By incorporating similar principles, future foundation models could develop more robust understanding of spatio-temporal systems that generalizes better to novel scenarios.

The unitary architecture of renormalization in quantum field theory offers another perspective on how fundamental physical principles could inform model design [20]. The bootstrap problem for renormalization, with its recursion relations between scattering amplitudes of different multiplicities, reveals deep connections between unitarity and renormalization that could inspire new architectural elements for STFMs. While the direct application of quantum field theory concepts to machine learning remains speculative, the mathematical structures involved may offer valuable insights for capturing multi-scale phenomena in spatio-temporal systems.

The integration of explicit physical constraints represents a more immediate approach to grounding STFMs in fundamental principles. By incorporating conservation laws, symmetry properties, or known physical relationships directly into model architectures or training procedures

## References

[1] Zack Dewis, Yimin Zhu, Zhengsen Xu et al. (2025). Multitask GLocal OBIA-Mamba for Sentinel-2 Landcover Mapping. http://arxiv.org/abs/2511.10604

[2] Raghav Adhikari, Sachet Khatiwada, Suman Poudel (2025). Optimizing the flight path for a scouting Uncrewed Aerial Vehicle. http://arxiv.org/abs/2511.10598

[3] Edward Kim, Devan Shanker, Varun Bharadwaj et al. (2025). Querying Labeled Time Series Data with Scenario Programs. http://arxiv.org/abs/2511.10627

[4] Jiang Liu, Jialian Wu, Xiaodong Yu et al. (2025). Instella: Fully Open Language Models with Stellar Performance. http://arxiv.org/abs/2511.10628

[5] Shruti Singh Baghel, Yash Pratap Singh Rathore, Sushovan Jena et al. (2025). Towards Blind and Low-Vision Accessibility of Lightweight VLMs and Custom LLM-Evals. http://arxiv.org/abs/2511.10615

[6] Yesheng Liang, Haisheng Chen, Song Han et al. (2025). ParoQuant: Pairwise Rotation Quantization for Efficient Reasoning LLM Inference. http://arxiv.org/abs/2511.10645

[7] Aleksandr Razin, Danil Kazantsev, Ilya Makarov (2025). One Small Step in Latent, One Giant Leap for Pixels: Fast Latent Upscale Adapter for Your Diffusion Models. http://arxiv.org/abs/2511.10629

[8] Haizhou Shi, Ye Liu, Bo Pang et al. (2025). SSR: Socratic Self-Refine for Large Language Model Reasoning. http://arxiv.org/abs/2511.10621

[9] Thomas Harvey, Christopher C. Lovell, Sophie Newman et al. (2025). Flexible Simulation Based Inference for Galaxy Photometric Fitting with Synthesizer. http://arxiv.org/abs/2511.10640

[10] Ahmed Gamal Eldin (2025). The Resonance Principle: Empirical Evidence for Emergent Phase Synchronization in Human Causal Reasoning. http://arxiv.org/abs/2511.10596

[11] Tianzhu Ye, Li Dong, Zewen Chi et al. (2025). Black-Box On-Policy Distillation of Large Language Models. http://arxiv.org/abs/2511.10643

[12] Yen Nhi Truong Vu, Dan Guo, Sripad Joshi et al. (2025). From 2D to 3D Without Extra Baggage: Data-Efficient Cancer Detection in Digital Breast Tomosynthesis. http://arxiv.org/abs/2511.10597

[13] Irene Abril-Cabezas, Frank J. Qu, Joshua Kim et al. (2025). The Atacama Cosmology Telescope. CMB Lensing from Daytime Data: A First Demonstration. http://arxiv.org/abs/2511.10620

[14] Maninder Kaur, Nicolas T. Sandino, Jason P. Terry et al. (2025). Excitonic Landscapes in Monolayer Lateral Heterostructures Revealed by Unsupervised Machine Learning. http://arxiv.org/abs/2511.10600

[15] I. Khayr, N. Somun, S. Hameed et al. (2025). Uniaxial strain tuning of polar lattice vibrations in KTaO$_3$ and SrTiO$_3$. http://arxiv.org/abs/2511.10623

[16] Dan Mao, Eun-Ah Kim (2025). Supernematic. http://arxiv.org/abs/2511.10642

[17] Neil J. Cornish (2025). Non-stationary noise in gravitational wave analyses: The wavelet domain noise covariance matrix. http://arxiv.org/abs/2511.10632

[18] Abdullah Khalid, Allyson Silva, Gebremedhin A. Dagnew et al. (2025). Impacts of Decoder Latency on Utility-Scale Quantum Computer Architectures. http://arxiv.org/abs/2511.10633

[19] Armeen Taeb, F. Richard Guo, Leonard Henckel (2025). Model-oriented Graph Distances via Partially Ordered Sets. http://arxiv.org/abs/2511.10625

[20] Ameya Chavda, Daniel McLoughlin, Sebastian Mizera et al. (2025). The Unitary Architecture of Renormalization. http://arxiv.org/abs/2511.10613
